import cv2
import os

# # ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸°
# # img_path = 'ì• êµ­ê°€.jpeg'
# image = cv2.imread(img_path)

# ê·¸ë ˆì´ ìŠ¤ì¼€ì¼ ë° ì´ì§„í™” 

def threshold_img(image):
    if len(image.shape) == 3:
        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)
    return image

import numpy as np
def remove_noise(image):
    image = threshold_img(image)  # ì´ë¯¸ì§€ ì´ì§„í™”
    mask = np.zeros(image.shape, np.uint8)  # ë³´í‘œ ì˜ì—­ë§Œ ì¶”ì¶œí•˜ê¸° ìœ„í•´ ë§ˆìŠ¤í¬ ìƒì„±

    cnt, labels, stats, centroids = cv2.connectedComponentsWithStats(image)  # ë ˆì´ë¸”ë§
    for i in range(1, cnt):
        x, y, w, h, area = stats[i]
        if w > image.shape[1] * 0.5:  # ë³´í‘œ ì˜ì—­ì—ë§Œ
            cv2.rectangle(mask, (x, y, w, h), (255, 0, 0), -1)  # ì‚¬ê°í˜• ê·¸ë¦¬ê¸°

    masked_image = cv2.bitwise_and(image, mask)  # ë³´í‘œ ì˜ì—­ ì¶”ì¶œ

    return masked_image

def remove_staves(image):
    height, width = image.shape
    staves = []  # ì˜¤ì„ ì˜ ì¢Œí‘œë“¤ì´ ì €ì¥ë  ë¦¬ìŠ¤íŠ¸

    for row in range(height):
        pixels = 0
        for col in range(width):
            pixels += (image[row][col] == 255)  # í•œ í–‰ì— ì¡´ì¬í•˜ëŠ” í°ìƒ‰ í”½ì…€ì˜ ê°œìˆ˜ë¥¼ ì…ˆ
        if pixels >= width * 0.5:  # ì´ë¯¸ì§€ ë„“ì´ì˜ 50% ì´ìƒì´ë¼ë©´
            if len(staves) == 0 or abs(staves[-1][0] + staves[-1][1] - row) > 1:  # ì²« ì˜¤ì„ ì´ê±°ë‚˜ ì´ì „ì— ê²€ì¶œëœ ì˜¤ì„ ê³¼ ë‹¤ë¥¸ ì˜¤ì„ 
                staves.append([row, 0])  # ì˜¤ì„  ì¶”ê°€ [ì˜¤ì„ ì˜ y ì¢Œí‘œ][ì˜¤ì„  ë†’ì´]
            else:  # ì´ì „ì— ê²€ì¶œëœ ì˜¤ì„ ê³¼ ê°™ì€ ì˜¤ì„ 
                staves[-1][1] += 1  # ë†’ì´ ì—…ë°ì´íŠ¸

    for staff in range(len(staves)):
        top_pixel = staves[staff][0]  # ì˜¤ì„ ì˜ ìµœìƒë‹¨ y ì¢Œí‘œ
        bot_pixel = staves[staff][0] + staves[staff][1]  # ì˜¤ì„ ì˜ ìµœí•˜ë‹¨ y ì¢Œí‘œ (ì˜¤ì„ ì˜ ìµœìƒë‹¨ y ì¢Œí‘œ + ì˜¤ì„  ë†’ì´)
        for col in range(width):
            if image[top_pixel - 1][col] == 0 and image[bot_pixel + 1][col] == 0:  # ì˜¤ì„  ìœ„, ì•„ë˜ë¡œ í”½ì…€ì´ ìˆëŠ”ì§€ íƒìƒ‰
                for row in range(top_pixel, bot_pixel + 1):
                    image[row][col] = 0  # ì˜¤ì„ ì„ ì§€ì›€

    return image, [x[0] for x in staves]

def normalization(image, staves, standard):
    if len(staves) < 6:  # ìµœì†Œ ì˜¤ì„  í•˜ë‚˜(5ì¤„)ë„ ì•ˆ ë  ê²½ìš°
        print("âš ï¸ ê°ì§€ëœ ì˜¤ì„  ìˆ˜ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
        return image, staves  # ê·¸ëŒ€ë¡œ ë°˜í™˜

    avg_distance = 0
    lines = int(len(staves) / 5)  # ë³´í‘œ(5ì¤„ ê¸°ì¤€)ì˜ ê°œìˆ˜
    for line in range(lines):
        for staff in range(4):
            staff_above = staves[line * 5 + staff]
            staff_below = staves[line * 5 + staff + 1]
            avg_distance += abs(staff_above - staff_below)

    denominator = len(staves) - lines
    if denominator == 0:
        print("âš ï¸ ë‚˜ëˆ—ì…ˆ 0 ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ avg_distance ê³„ì‚°ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
        return image, [0 for _ in staves]  # head_centerì™€ ìœ ì‚¬í•œ ë™ì‘ì„ ìœ„í•´ staves ëª¨ë‘ 0ìœ¼ë¡œ ë°˜í™˜

    avg_distance /= denominator

    height, width = image.shape
    weight = standard / avg_distance
    new_width = int(width * weight)
    new_height = int(height * weight)

    image = cv2.resize(image, (new_width, new_height))
    ret, image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
    staves = [x * weight for x in staves]

    return image, staves

def weighted(value):
    standard = 10
    return int(value * (standard / 10))

def closing(image):
    kernel = np.ones((weighted(5), weighted(5)), np.uint8)
    image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)
    return image

def put_text(image, text, loc):
    font = cv2.FONT_HERSHEY_SIMPLEX
    cv2.putText(image, str(text), loc, font, 0.6, (255, 0, 0), 2)
    
def get_center(y, h):
    return (y + y + h) / 2

def object_detection(image, staves):
    lines = int(len(staves) / 5)  # ë³´í‘œì˜ ê°œìˆ˜
    objects = []  # êµ¬ì„±ìš”ì†Œ ì •ë³´ê°€ ì €ì¥ë  ë¦¬ìŠ¤íŠ¸

    closing_image = closing(image)
    cnt, labels, stats, centroids = cv2.connectedComponentsWithStats(closing_image)  # ëª¨ë“  ê°ì²´ ê²€ì¶œí•˜ê¸°
    for i in range(1, cnt):
        (x, y, w, h, area) = stats[i]
        if w >= weighted(5) and h >= weighted(5):  # ì•…ë³´ì˜ êµ¬ì„±ìš”ì†Œê°€ ë˜ê¸° ìœ„í•œ ë„“ì´, ë†’ì´ ì¡°ê±´
            center = get_center(y, h)
            for line in range(lines):
                area_top = staves[line * 5] - weighted(20)  # ìœ„ì¹˜ ì¡°ê±´ (ìƒë‹¨)
                area_bot = staves[(line + 1) * 5 - 1] + weighted(20)  # ìœ„ì¹˜ ì¡°ê±´ (í•˜ë‹¨)
                if area_top <= center <= area_bot:
                    objects.append([line, (x, y, w, h, area)])  # ê°ì²´ ë¦¬ìŠ¤íŠ¸ì— ë³´í‘œ ë²ˆí˜¸ì™€ ê°ì²´ì˜ ì •ë³´(ìœ„ì¹˜, í¬ê¸°)ë¥¼ ì¶”ê°€

    objects.sort()  # ë³´í‘œ ë²ˆí˜¸ â†’ x ì¢Œí‘œ ìˆœìœ¼ë¡œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬

    return image, objects

VERTICAL = True
HORIZONTAL = False

def get_line(image, axis, axis_value, start, end, length):
    if axis:
        points = [(i, axis_value) for i in range(start, end)]  # ìˆ˜ì§ íƒìƒ‰
    else:
        points = [(axis_value, i) for i in range(start, end)]  # ìˆ˜í‰ íƒìƒ‰
    pixels = 0
    for i in range(len(points)):
        (y, x) = points[i]
        pixels += (image[y][x] == 255)  # í°ìƒ‰ í”½ì…€ì˜ ê°œìˆ˜ë¥¼ ì…ˆ
        next_point = image[y + 1][x] if axis else image[y][x + 1]  # ë‹¤ìŒ íƒìƒ‰í•  ì§€ì 
        if next_point == 0 or i == len(points) - 1:  # ì„ ì´ ëŠê¸°ê±°ë‚˜ ë§ˆì§€ë§‰ íƒìƒ‰ì„
            if pixels >= weighted(length):
                break  # ì°¾ëŠ” ê¸¸ì´ì˜ ì§ì„ ì„ ì°¾ì•˜ìœ¼ë¯€ë¡œ íƒìƒ‰ì„ ì¤‘ì§€í•¨
            else:
                pixels = 0  # ì°¾ëŠ” ê¸¸ì´ì— ë„ë‹¬í•˜ê¸° ì „ì— ì„ ì´ ëŠê¹€ (ë‚¨ì€ ë²”ìœ„ ë‹¤ì‹œ íƒìƒ‰)
    return y if axis else x, pixels

def stem_detection(image, stats, length):
    (x, y, w, h, area) = stats
    stems = []  # ê¸°ë‘¥ ì •ë³´ (x, y, w, h)
    for col in range(x, x + w):
        end, pixels = get_line(image, VERTICAL, col, y, y + h, length)
        if pixels:
            if len(stems) == 0 or abs(stems[-1][0] + stems[-1][2] - col) >= 1:
                (x, y, w, h) = col, end - pixels + 1, 1, pixels
                stems.append([x, y, w, h])
            else:
                stems[-1][2] += 1
    return stems

def object_analysis(image, objects):
    for obj in objects:
        stats = obj[1]
        stems = stem_detection(image, stats, 30)  # ê°ì²´ ë‚´ì˜ ëª¨ë“  ì§ì„ ë“¤ì„ ê²€ì¶œí•¨
        direction = None
        if len(stems) > 0:  # ì§ì„ ì´ 1ê°œ ì´ìƒ ì¡´ì¬í•¨
            if stems[0][0] - stats[0] >= weighted(5):  # ì§ì„ ì´ ë‚˜ì¤‘ì— ë°œê²¬ë˜ë©´
                direction = True  # ì • ë°©í–¥ ìŒí‘œ
            else:  # ì§ì„ ì´ ì¼ì° ë°œê²¬ë˜ë©´
                direction = False  # ì—­ ë°©í–¥ ìŒí‘œ
        obj.append(stems)  # ê°ì²´ ë¦¬ìŠ¤íŠ¸ì— ì§ì„  ë¦¬ìŠ¤íŠ¸ë¥¼ ì¶”ê°€
        obj.append(direction)  # ê°ì²´ ë¦¬ìŠ¤íŠ¸ì— ìŒí‘œ ë°©í–¥ì„ ì¶”ê°€

    return image, objects

def recognize_key(image, staves, stats):
    (x, y, w, h, area) = stats
    ts_conditions = (
        staves[0] + weighted(5) >= y >= staves[0] - weighted(5) and  # ìƒë‹¨ ìœ„ì¹˜ ì¡°ê±´
        staves[4] + weighted(5) >= y + h >= staves[4] - weighted(5) and  # í•˜ë‹¨ ìœ„ì¹˜ ì¡°ê±´
        staves[2] + weighted(5) >= get_center(y, h) >= staves[2] - weighted(5) and  # ì¤‘ë‹¨ ìœ„ì¹˜ ì¡°ê±´
        weighted(18) >= w >= weighted(10) and  # ë„“ì´ ì¡°ê±´
        weighted(45) >= h >= weighted(35)  # ë†’ì´ ì¡°ê±´
    )
    if ts_conditions:
        return True, 0
    else:  # ì¡°í‘œê°€ ìˆì„ ê²½ìš° (ë‹¤ì¥ì¡°ë¥¼ ì œì™¸í•œ ëª¨ë“  ì¡°)
        stems = stem_detection(image, stats, 20)
        if stems[0][0] - x >= weighted(3):  # ì§ì„ ì´ ë‚˜ì¤‘ì— ë°œê²¬ë˜ë©´
            key = int(10 * len(stems) / 2)  # ìƒ¾
        else:  # ì§ì„ ì´ ì¼ì° ë°œê²¬ë˜ë©´
            key = 100 * len(stems)  # í”Œë«

    return False, key

def count_rect_pixels(image, rect):
    x, y, w, h = rect
    pixels = 0
    for row in range(y, y + h):
        for col in range(x, x + w):
            if image[row][col] == 255:
                pixels += 1
    return pixels

def recognize_note_head(image, stem, direction):
    (x, y, w, h) = stem
    if direction:  # ì • ë°©í–¥ ìŒí‘œ
        area_top = y + h - weighted(7)  # ìŒí‘œ ë¨¸ë¦¬ë¥¼ íƒìƒ‰í•  ìœ„ì¹˜ (ìƒë‹¨)
        area_bot = y + h + weighted(7)  # ìŒí‘œ ë¨¸ë¦¬ë¥¼ íƒìƒ‰í•  ìœ„ì¹˜ (í•˜ë‹¨)
        area_left = x - weighted(14)  # ìŒí‘œ ë¨¸ë¦¬ë¥¼ íƒìƒ‰í•  ìœ„ì¹˜ (ì¢Œì¸¡)
        area_right = x  # ìŒí‘œ ë¨¸ë¦¬ë¥¼ íƒìƒ‰í•  ìœ„ì¹˜ (ìš°ì¸¡)
    else:  # ì—­ ë°©í–¥ ìŒí‘œ
        area_top = y - weighted(7)  # ìŒí‘œ ë¨¸ë¦¬ë¥¼ íƒìƒ‰í•  ìœ„ì¹˜ (ìƒë‹¨)
        area_bot = y + weighted(7)  # ìŒí‘œ ë¨¸ë¦¬ë¥¼ íƒìƒ‰í•  ìœ„ì¹˜ (í•˜ë‹¨)
        area_left = x + w  # ìŒí‘œ ë¨¸ë¦¬ë¥¼ íƒìƒ‰í•  ìœ„ì¹˜ (ì¢Œì¸¡)
        area_right = x + w + weighted(14)  # ìŒí‘œ ë¨¸ë¦¬ë¥¼ íƒìƒ‰í•  ìœ„ì¹˜ (ìš°ì¸¡)

    cnt = 0  # cnt = ëŠê¸°ì§€ ì•Šê³  ì´ì–´ì ¸ ìˆëŠ” ì„ ì˜ ê°œìˆ˜ë¥¼ ì…ˆ
    cnt_max = 0  # cnt_max = cnt ì¤‘ ê°€ì¥ í° ê°’
    head_center = 0
    pixel_cnt = count_rect_pixels(image, (area_left, area_top, area_right - area_left, area_bot - area_top))

    for row in range(area_top, area_bot):
        col, pixels = get_line(image, HORIZONTAL, row, area_left, area_right, 5)
        pixels += 1
        if pixels >= weighted(5):
            cnt += 1
            cnt_max = max(cnt_max, pixels)
            head_center += row

    head_exist = (cnt >= 3 and pixel_cnt >= 50)
    head_fill = (cnt >= 8 and cnt_max >= 9 and pixel_cnt >= 80)
    
    if cnt == 0:
        return False, False, np.array([0, 0])
    
    head_center /= cnt

    return head_exist, head_fill, head_center

def count_pixels_part(image, area_top, area_bot, area_col):
    cnt = 0
    flag = False
    for row in range(area_top, area_bot):
        if not flag and image[row][area_col] == 255:
            flag = True
            cnt += 1
        elif flag and image[row][area_col] == 0:
            flag = False
    return cnt

def recognize_note_tail(image, index, stem, direction):
    (x, y, w, h) = stem
    if direction:  # ì • ë°©í–¥ ìŒí‘œ
        area_top = y  # ìŒí‘œ ê¼¬ë¦¬ë¥¼ íƒìƒ‰í•  ìœ„ì¹˜ (ìƒë‹¨)
        area_bot = y + h - weighted(15)  # ìŒí‘œ ê¼¬ë¦¬ë¥¼ íƒìƒ‰í•  ìœ„ì¹˜ (í•˜ë‹¨)
    else:  # ì—­ ë°©í–¥ ìŒí‘œ
        area_top = y + weighted(15)  # ìŒí‘œ ê¼¬ë¦¬ë¥¼ íƒìƒ‰í•  ìœ„ì¹˜ (ìƒë‹¨)
        area_bot = y + h  # ìŒí‘œ ê¼¬ë¦¬ë¥¼ íƒìƒ‰í•  ìœ„ì¹˜ (í•˜ë‹¨)
    if index:
        area_col = x - weighted(4)  # ìŒí‘œ ê¼¬ë¦¬ë¥¼ íƒìƒ‰í•  ìœ„ì¹˜ (ì—´)
    else:
        area_col = x + w + weighted(4)  # ìŒí‘œ ê¼¬ë¦¬ë¥¼ íƒìƒ‰í•  ìœ„ì¹˜ (ì—´)

    cnt = count_pixels_part(image, area_top, area_bot, area_col)

    return cnt

def recognize_note_dot(image, stem, direction, tail_cnt, stems_cnt):
    (x, y, w, h) = stem
    if direction:  # ì • ë°©í–¥ ìŒí‘œ
        area_top = y + h - weighted(10)  # ìŒí‘œ ì ì„ íƒìƒ‰í•  ìœ„ì¹˜ (ìƒë‹¨)
        area_bot = y + h + weighted(5)  # ìŒí‘œ ì ì„ íƒìƒ‰í•  ìœ„ì¹˜ (í•˜ë‹¨)
        area_left = x + w + weighted(2)  # ìŒí‘œ ì ì„ íƒìƒ‰í•  ìœ„ì¹˜ (ì¢Œì¸¡)
        area_right = x + w + weighted(12)  # ìŒí‘œ ì ì„ íƒìƒ‰í•  ìœ„ì¹˜ (ìš°ì¸¡)
    else:  # ì—­ ë°©í–¥ ìŒí‘œ
        area_top = y - weighted(10)  # ìŒí‘œ ì ì„ íƒìƒ‰í•  ìœ„ì¹˜ (ìƒë‹¨)
        area_bot = y + weighted(5)  # ìŒí‘œ ì ì„ íƒìƒ‰í•  ìœ„ì¹˜ (í•˜ë‹¨)
        area_left = x + w + weighted(14)  # ìŒí‘œ ì ì„ íƒìƒ‰í•  ìœ„ì¹˜ (ì¢Œì¸¡)
        area_right = x + w + weighted(24)  # ìŒí‘œ ì ì„ íƒìƒ‰í•  ìœ„ì¹˜ (ìš°ì¸¡)
    dot_rect = (
        area_left,
        area_top,
        area_right - area_left,
        area_bot - area_top
    )

    pixels = count_rect_pixels(image, dot_rect)

    threshold = (10, 15, 20, 30)
    if direction and stems_cnt == 1:
        return pixels >= weighted(threshold[tail_cnt])
    else:
        return pixels >= weighted(threshold[0])

def recognize_pitch(image, staff, head_center):
    pitch_lines = [staff[4] + weighted(30) - weighted(5) * i for i in range(21)]

    for i in range(len(pitch_lines)):
        line = pitch_lines[i]
        if line + weighted(2) >= head_center >= line - weighted(2):
            return i

def recognize_rest_dot(image, stats):
    (x, y, w, h, area) = stats
    area_top = y - weighted(10)  # ì‰¼í‘œ ì ì„ íƒìƒ‰í•  ìœ„ì¹˜ (ìƒë‹¨)
    area_bot = y + weighted(10)  # ì‰¼í‘œ ì ì„ íƒìƒ‰í•  ìœ„ì¹˜ (í•˜ë‹¨)
    area_left = x + w  # ì‰¼í‘œ ì ì„ íƒìƒ‰í•  ìœ„ì¹˜ (ì¢Œì¸¡)
    area_right = x + w + weighted(10)  # ì‰¼í‘œ ì ì„ íƒìƒ‰í•  ìœ„ì¹˜ (ìš°ì¸¡)
    dot_rect = (
        area_left,
        area_top,
        area_right - area_left,
        area_bot - area_top
    )

    pixels = count_rect_pixels(image, dot_rect)

    return pixels >= weighted(10)

def recognition(image, staves, objects):
    import os
    from pathlib import Path

    key = 0
    time_signature = False
    beats = []  # ë°•ì ë¦¬ìŠ¤íŠ¸
    pitches = []  # ìŒì´ë¦„ ë¦¬ìŠ¤íŠ¸

    # ì €ì¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    save_dir = Path("cropped_notes_from_recognition")
    save_dir.mkdir(parents=True, exist_ok=True)

    # binary ì´ë¯¸ì§€ ìƒì„± (cropì— ì‚¬ìš©)
    binary = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

    for i in range(1, len(objects) - 1):
        obj = objects[i]
        line = obj[0]
        stats = obj[1]
        stems = obj[2]
        direction = obj[3]
        (x, y, w, h, area) = stats
        staff = staves[line * 5: (line + 1) * 5]

        if not time_signature:
            ts, temp_key = recognize_key(image, staff, stats)
            time_signature = ts
            key += temp_key
            if time_signature:
                put_text(image, key, (x, y + h + weighted(30)))
        else:
            notes = recognize_note(image, staff, stats, stems, direction)
            if len(notes[0]):
                for beat in notes[0]:
                    beats.append(beat)
                for pitch in notes[1]:
                    pitches.append(pitch)

                # ğŸ”¥ ìŒí‘œ ê°ì²´ crop ë° ì €ì¥
                cropped = binary[y:y+h, x:x+w]
                resized = cv2.resize(cropped, (299, 299), interpolation=cv2.INTER_AREA)
                save_path = save_dir / f"note_{i:03}.png"
                cv2.imwrite(str(save_path), resized)

            else:
                rest = recognize_rest(image, staff, stats)
                if rest:
                    beats.append(rest)
                    pitches.append(-1)

                    # ğŸ”¥ ì‰¼í‘œë„ cropí•´ì„œ ì €ì¥
                    cropped = binary[y:y+h, x:x+w]
                    resized = cv2.resize(cropped, (299, 299), interpolation=cv2.INTER_AREA)
                    save_path = save_dir / f"rest_{i:03}.png"
                    cv2.imwrite(str(save_path), resized)

                else:
                    whole_note, pitch = recognize_whole_note(image, staff, stats)
                    if whole_note:
                        beats.append(whole_note)
                        pitches.append(pitch)

                        # ğŸ”¥ ì˜¨ìŒí‘œ crop ì €ì¥
                        cropped = binary[y:y+h, x:x+w]
                        resized = cv2.resize(cropped, (299, 299), interpolation=cv2.INTER_AREA)
                        save_path = save_dir / f"whole_{i:03}.png"
                        cv2.imwrite(str(save_path), resized)

        cv2.rectangle(image, (x, y, w, h), (255, 0, 0), 1)
        put_text(image, i, (x, y - weighted(20)))

    return image, key, beats, pitches



def recognize_note(image, staff, stats, stems, direction):
    (x, y, w, h, area) = stats
    notes = []
    pitches = []
    note_condition = (
            len(stems) and
            w >= weighted(10) and  # ë„“ì´ ì¡°ê±´
            h >= weighted(35) and  # ë†’ì´ ì¡°ê±´
            area >= weighted(95)  # í”½ì…€ ê°¯ìˆ˜ ì¡°ê±´
    )
    if note_condition:
        for i in range(len(stems)):
            stem = stems[i]
            head_exist, head_fill, head_center = recognize_note_head(image, stem, direction)
            if head_exist:
                tail_cnt = recognize_note_tail(image, i, stem, direction)
                dot_exist = recognize_note_dot(image, stem, direction, len(stems), tail_cnt)
                note_classification = (
                    ((not head_fill and tail_cnt == 0 and not dot_exist), 2),
                    ((not head_fill and tail_cnt == 0 and dot_exist), -2),
                    ((head_fill and tail_cnt == 0 and not dot_exist), 4),
                    ((head_fill and tail_cnt == 0 and dot_exist), -4),
                    ((head_fill and tail_cnt == 1 and not dot_exist), 8),
                    ((head_fill and tail_cnt == 1 and dot_exist), -8),
                    ((head_fill and tail_cnt == 2 and not dot_exist), 16),
                    ((head_fill and tail_cnt == 2 and dot_exist), -16),
                    ((head_fill and tail_cnt == 3 and not dot_exist), 32),
                    ((head_fill and tail_cnt == 3 and dot_exist), -32)
                )

                for j in range(len(note_classification)):
                    if note_classification[j][0]:
                        note = note_classification[j][1]
                        pitch = recognize_pitch(image, staff, head_center)
                        notes.append(note)
                        pitches.append(pitch)
                        put_text(image, note, (stem[0] - weighted(10), stem[1] + stem[3] + weighted(30)))
                        put_text(image, pitch, (stem[0] - weighted(10), stem[1] + stem[3] + weighted(60)))
                        break

    return notes, pitches


def recognize_rest(image, staff, stats):
    (x, y, w, h, area) = stats
    rest = 0
    center = get_center(y, h)
    rest_condition = staff[3] > center > staff[1]
    if rest_condition:
        cnt = count_pixels_part(image, y, y + h, x + weighted(1))
        if weighted(35) >= h >= weighted(25):
            if cnt == 3 and weighted(11) >= w >= weighted(7):
                rest = 4
            elif cnt == 1 and weighted(14) >= w >= weighted(11):
                rest = 16
        elif weighted(22) >= h >= weighted(16):
            if weighted(15) >= w >= weighted(9):
                rest = 8
        elif weighted(8) >= h:
            if staff[1] + weighted(5) >= center >= staff[1]:
                rest = 1
            elif staff[2] >= center >= staff[1] + weighted(5):
                rest = 2
        if recognize_rest_dot(image, stats):
            rest *= -1
        if rest:
            put_text(image, rest, (x, y + h + weighted(30)))
            put_text(image, -1, (x, y + h + weighted(60)))

    return rest


def recognize_whole_note(image, staff, stats):
    whole_note = 0
    pitch = 0
    (x, y, w, h, area) = stats
    while_note_condition = (
            weighted(22) >= w >= weighted(12) >= h >= weighted(9)
    )
    if while_note_condition:
        dot_rect = (
            x + w,
            y - weighted(10),
            weighted(10),
            weighted(20)
        )
        pixels = count_rect_pixels(image, dot_rect)
        whole_note = -1 if pixels >= weighted(10) else 1
        pitch = recognize_pitch(image, staff, get_center(y, h))
        put_text(image, whole_note, (x, y + h + weighted(30)))
        put_text(image, pitch, (x, y + h + weighted(60)))

    return whole_note, pitch

def draw_staves(image, staves, color=(0, 0, 0), thickness=1):
    # === 1. ìƒ‰ ë°˜ì „: í‘ë°°ê²½ â†’ ë°±ë°°ê²½
    if len(image.shape) == 2:
        image = cv2.bitwise_not(image)                     # ë°˜ì „
        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)    # ì»¬ëŸ¬ë¡œ ë³€í™˜
    else:
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        image = cv2.bitwise_not(gray)
        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)

    # === 2. ì˜¤ì„  ê·¸ë¦¬ê¸°
    for line_y in staves:
        cv2.line(image, (0, int(line_y)), (image.shape[1], int(line_y)), color, thickness)

    return image

def resize_with_padding(image, target_size=299, max_scale=4.0):
    h, w = image.shape[:2]

    # í™•ëŒ€ ë¹„ìœ¨ ê²°ì • (ìµœëŒ€ 4ë°°ê¹Œì§€ë§Œ í™•ëŒ€)
    scale = min(target_size / max(h, w), max_scale)

    new_w, new_h = int(w * scale), int(h * scale)

    # í™•ëŒ€
    resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)

    # ì¤‘ì•™ ë°°ì¹˜ ìœ„í•œ ì—¬ë°± ê³„ì‚°
    top = (target_size - new_h) // 2
    bottom = target_size - new_h - top
    left = (target_size - new_w) // 2
    right = target_size - new_w - left

    # í°ìƒ‰ ì—¬ë°± ì¶”ê°€
    padded = cv2.copyMakeBorder(
        resized, top, bottom, left, right,
        borderType=cv2.BORDER_CONSTANT,
        value=[255, 255, 255]
    )

    return padded



